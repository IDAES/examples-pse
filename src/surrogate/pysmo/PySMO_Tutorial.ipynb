{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PySMO Tutorial\n",
        "\n",
        "**Python-based Surrogate Modelling Objects** (PySMO) provides tools for generating different types of reduced order models. PySMO currently provides tools for sampling and surrogate model generation.\n",
        "\n",
        "## Installation\n",
        "\n",
        "**PySMO** is installed by default as part of IDAES. For instructions on installing IDAES, see the [online documentation](https://idaes-pse.readthedocs.io/en/stable/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## One-Shot Sampling with PySMO\n",
        "\n",
        "The PySMO package offers five common sampling methods for one-shot design:\n",
        "\n",
        "* Latin Hypercube Sampling (LHS)\n",
        "* Full-Factorial Sampling\n",
        "* Halton Sampling\n",
        "* Hammersley Sampling\n",
        "* Centroidal voronoi tessellation (CVT) sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PySMO provides two modes for data sampling: creation and selection.\n",
        "- In creation mode, PySMO creates a specified number of sample points from the bounds provided by the user.\n",
        "- In selection mode, PySMO selects a specified number of data points from a user-supplied dataset or file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generating samples: \n",
        "For demonstration purposes, let us consider a problem for which we need twenty-five (25) samples of temperature and pressure from within the ranges T = 273K - 373K, P = 1 MPa - 50 MPa. Let us generate these samples in PySMO."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 1: Import PySMO's sampling tool\n",
        "For this demonstration, we will attempt to generate the samples using the Hammersley sampling method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from idaes.surrogate.pysmo.sampling import HammersleySampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 2: Specify sampling information and initialize class\n",
        "\n",
        "All the sampling tools (except full-factorial sampling) require the same keyword arguments:\n",
        "\n",
        "          -  data_input             : must be a list of lists containing the problem bounds (when creating points), \n",
        "                                      or an input dataset (when selecting points from a dataset)\n",
        "          -  number_of_samples      : number of samples to be created or selected.\n",
        "          -  sampling_type          : \"creation\" or \"selection\".\n",
        "\n",
        "For full factorial sampling, the user needs to enter a list of points in each dimension in place of the number of samples. Full-factorial sampling requires other inputs - details may be found in the [documentation](https://idaes-pse.readthedocs.io/en/stable/surrogate/pysmo/index.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For our example, we will create the bounds and then initialize the class with the number of samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "bounds_info = [[273, 1],[373, 50]]\n",
        "init_data = HammersleySampling(data_input=bounds_info, number_of_samples=25, sampling_type=\"creation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 3: Create the samples\n",
        "The samples are created by calling the ``sample_points`` method on the initialized class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "samples = init_data.sample_points()\n",
        "print(samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simple as that, the samples have been created!\n",
        "\n",
        "Now, let us visualize the samples in a 2-D plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 4: Visualize samples with matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(samples[:, 0], samples[:, 1], 'o')\n",
        "plt.xlabel(r'Temperature', fontsize=11)\n",
        "plt.xlabel(r'Pressure', fontsize=11)\n",
        "plt.xlim(272, 374)\n",
        "plt.ylim(0, 50)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating surrogates with PySMO\n",
        "\n",
        "PySMO currently provides tools for generating three types of surrogates:\n",
        "\n",
        "- Polynomial surrogates\n",
        "- Radial basis function (RBF) surrogates, and\n",
        "- Kriging surrogates\n",
        "\n",
        "Details about thee various methods may be found in the [documentation](https://idaes-pse.readthedocs.io/en/stable/surrogate/pysmo/index.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generating polynomial models\n",
        "\n",
        "The ``PolynomialRegression`` class trains polynomial models from data.\n",
        "\n",
        "As an example, let us generate a surrogate for the Brainin function. \n",
        "\n",
        "The true Brainin function is given by the expression:\n",
        " \n",
        " \\begin{gather}\n",
        "\\hat{y}(x_{1},x_{2})=\\left(x_{2}-\\frac{5.1x_{1}^{2}}{4\\pi^{2}}+\\frac{5x_{1}}{\\pi}-6\\right)^{2}+10\\left[\\left(1-\\frac{1}{8\\pi}\\right)\\cos\\left(x_{1}\\right)+1\\right]+5x_{1}\\nonumber \\\\\n",
        "x_{1}\\in\\left[-5,10\\right];x_{2}\\in\\left[0,15\\right]\n",
        "\\end{gather}\n",
        "\n",
        "We have generated 30 points from the function and saved the information in a text file called \"brainin_30.txt\". We will use this data to train a simple polynomial model. The data is in XY format, with the outputs $y$ in the third column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 1: Import and visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "brainin_data = np.loadtxt('brainin_30.txt')\n",
        "print(brainin_data,'\\n\\nDataset shape:', brainin_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us visualize the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D \n",
        "from matplotlib import pyplot as plt\n",
        "fig1 = plt.figure(figsize=(6, 4), tight_layout=True)\n",
        "ax = fig1.add_subplot(111, projection='3d')\n",
        "ax.scatter3D(brainin_data[:, 0], brainin_data[:, 1], brainin_data[:, 2], cmap=brainin_data[:, 2])\n",
        "ax.set_xlabel(r'$x_{1}$', fontsize=11)\n",
        "ax.set_ylabel(r'$x_{2}$', fontsize=11)\n",
        "ax.set_zlabel(r'$y$', fontsize=11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 2: Import the polynomial model tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from idaes.surrogate.pysmo.polynomial_regression import PolynomialRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 3: Specify the regression settings and initialize the PolynomialRegression class\n",
        "    \n",
        "The PolynomialRegression class takes a keyword arguments:\n",
        "\n",
        "      -  original_data_input           : The dataset for regression training. training_data is expected to contain xy_data, \n",
        "                                         with the output values (y) in the last column.\n",
        "      -  regression_data_input         : same as above\n",
        "      -  maximum_polynomial_order      : maximum order of the polynomial to be generated  \n",
        "\n",
        "It also takes a number of optional arguments:\n",
        "\n",
        "      - multinomials                  : True/False option for specifying second-order bi-variate terms. default is False\n",
        "      - training_split                : The training/cross-validation split of training data. Must be between 0 and 1. \n",
        "                                        Default is 0.75\n",
        "      - fname                         : Filename for saving results (.pickle extension). \n",
        "      - overwrite                     : Option determining whether any existing file with the same name supplied in 'fname'  \n",
        "                                        should be overwritten."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this example, let us consider a 4th order polynomial with interaction terms. We will split the data 80/20 betweeen training and cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "poly_class = PolynomialRegression(original_data_input=brainin_data, regression_data_input=brainin_data, \n",
        "                                  maximum_polynomial_order=4, multinomials=1, training_split=0.8, number_of_crossvalidations=10, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 4: Extract variable names\n",
        "Next, we extract Pyomo variable names from the dataset. This should be done always."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars = poly_class.get_feature_vector()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can view the variables using Pyomo's pprint function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars.pprint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 5: Specify additional regression terms, if required.\n",
        "\n",
        "This is one of the unique features of PySMO -  it allows the user to specify additional regression features if they want.\n",
        "The additional features must be specified in terms of the Pyomo variables created when calling the ``get_feature_vector()`` \n",
        "\n",
        "For this example, let us create three additional features: $x_{1}^{2}x_{2}^{2}$, $exp(x_1)$ and $exp(x_2)$. We do this by calling the ``set_additional_terms`` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyomo.environ import exp\n",
        "poly_class.set_additional_terms([vars[0] * vars[0] * vars[1] * vars[1], exp(vars[0]), exp(vars[1])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's it - those features will now exist in the model. \n",
        "\n",
        "Note that ``set_additional_terms`` an optional call - the regression process works just fine without it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 6: Train the surrogate and view results\n",
        "Next, we train the polynomial surrogate by calling ``poly_training``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = poly_class.poly_training()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The polynomial model seems to fit well based on the $R^2$. It should be noted that the metrics are only an indication of how well of how well the model fit the training data - the user needs to verify the model's performance on a test data set if possible.\n",
        "\n",
        "We can view the parity and residual plots for the fit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "poly_class.parity_residual_plots(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PySMO is also able to compute the confidence intervals on the regression coefficients obtained by calling ``confint_regression()``. This is left as an exercise for the user.\n",
        "\n",
        "#### Step 8 (Optional): Generate Pyomo expression \n",
        "\n",
        "If the user wishes, they can generate the Pyomo expression for the polynomial fit using PySMO's ``generate_expression``.\n",
        "\n",
        "To do this, the user must pass in a list of Pyomo variables corresponding to each variable in the input dataset. The user should note that ``generate_expression`` should be called on the result object, not the class object.\n",
        "\n",
        "As a demonstration, let us create the variables $x_1$ and $x_2$ and generate the pyomo expression based on them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyomo.environ import Var, ConcreteModel\n",
        "m = ConcreteModel()\n",
        "m.x = Var([1, 2])\n",
        "print(result.generate_expression([m.x[1], m.x[2]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 9 (Optional): Predict output at any unsampled point\n",
        "\n",
        "Based on the model we trained, we can predict the surrogate value at any previously unsampled point. \n",
        "\n",
        "Let us evaluate the surrogate at three points:\n",
        "\n",
        "- $x_{1}=5$, $x_{2}=8$ (true function value: 57.9908)\n",
        "- $x_{1}=-3$, $x_{2}=10$ (true function value: 4.2461)\n",
        "- $x_{1}=-2$, $x_{2}=3$. (true function value: 50.8899)\n",
        "\n",
        "We will pass the points in as an array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "unsampled_points = np.array([ [5, 8], [-3, 10], [-2, 3]])\n",
        "ys = poly_class.poly_predict_output(result, unsampled_points)\n",
        "print(ys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model performs fairly well in predicting the value at two of our sampled points but is off on the value at [-3, 2]. For better model performance, additional training data is needed in this region. We will leave this to the user to try.\n",
        "\n",
        "Further information about using PySMO's polynomial regression tool can be found in the [documentation](https://idaes-pse.readthedocs.io/en/stable/surrogate/pysmo/pysmo_polyregression.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generating RBF models\n",
        "\n",
        "The ``RadialBasisFunction`` class trains RBF models from data. For details about RBF models, the user should consult the documentation.\n",
        "\n",
        "As an example, we will again consider the Brainin function. The same dataset loaded previously will be used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 1: Import the data and the RBF tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "brainin_data = np.loadtxt('brainin_30.txt')\n",
        "from idaes.surrogate.pysmo.radial_basis_function import RadialBasisFunctions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 2: Specify the RBF settings and initialize the RadialBasisFunctions class\n",
        "    \n",
        "The RadialBasisFunctions class takes a number of keyword arguments:\n",
        "\n",
        "      -  XY_data                       : The dataset forRBF training. training_data is expected to contain xy_data, \n",
        "                                         with the output values (y) in the last column.\n",
        "\n",
        "\n",
        "It also takes a number of optional arguments:\n",
        "\n",
        "      -  regularization                : Boolean variable determining whether regularization is done. Default is True.\n",
        "      -  basis_function                : Basis function transformation to be applied to the training data. PySMO offers \n",
        "                                         six basis function types including the Gaussian and Spline transformations. User \n",
        "                                         should consult documentation for full list of options.   \n",
        "      -  fname                         : Filename for saving (.pickle extension)\n",
        "      - overwrite                      : Option determining whether any existing file with the same name supplied in 'fname'  \n",
        "                                         should be overwritten."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this demonstration, we will train an RBF model with a Gaussian basis function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "rbf_class = RadialBasisFunctions(XY_data=brainin_data, basis_function='gaussian', overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 3: Extract variable names\n",
        "Next, we extract Pyomo variable names from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars = rbf_class.get_feature_vector()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 4: Train the RBF surrogate\n",
        "Next, we train the RBF surrogate by calling ``rbf_training``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = rbf_class.rbf_training()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 5: View model metrics\n",
        "    \n",
        "We can view the Root Mean Square Error (RMSE) and $R^2$ values of the RBF fit based on the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('R2: ', result.R2, '\\nRMSE: ', result.rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 6 (Optional): Generate Pyomo expression output at any unsampled point\n",
        "\n",
        "\n",
        "Based on the model we trained, we can predict the surrogate value at any previously unsampled point. We do this by calling the function ``rbf_predict_output``.\n",
        "\n",
        "Let us again evaluate the RBF surrogate at the same set of points we considered for the polynomial model:\n",
        "\n",
        "- $x_{1}=5$, $x_{2}=8$   (true function value: 57.9908)\n",
        "- $x_{1}=-3$, $x_{2}=10$ (true function value: 4.2461)\n",
        "- $x_{1}=-2$, $x_{2}=3$  (true function value: 50.8899)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "unsampled_points = np.array([ [5, 8], [-3, 10], [-2, 3]])\n",
        "ys = rbf_class.rbf_predict_output(result, unsampled_points)\n",
        "print(ys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results from the RBF surrogate are slightly better than those obtained form the polynomial.\n",
        "\n",
        "\n",
        "For RBF models, the Pyomo expression is generated by calling ``rbf_generate_expression`` on the results object, while parity plots may be viewed with the ``parity_residual_plots`` method.\n",
        "\n",
        "Further information about using PySMO's RBF tool and features can be found in the [documentation](https://idaes-pse.readthedocs.io/en/stable/surrogate/pysmo/pysmo_radialbasisfunctions.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Kriging models\n",
        "\n",
        "The ``KrigingModel`` class trains Kriging from data. For details about Kriging models, users should consult the documentation.\n",
        "\n",
        "As an example, we will again consider the Brainin function. The same dataset loaded previously will be used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 1: Load the data and import the Kriging tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "brainin_data = np.loadtxt('brainin_30.txt')\n",
        "from idaes.surrogate.pysmo.kriging import KrigingModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 2: Specify the Kriging settings and initialize the KrigingModel class\n",
        "    \n",
        "The KrigingModel class takes a number of keyword arguments:\n",
        "\n",
        "      -  XY_data                       : The dataset for Kriging training. training_data is expected to contain xy_data, \n",
        "                                         with the output values (y) in the last column.\n",
        "\n",
        "\n",
        "It also takes a number of optional arguments:\n",
        "\n",
        "      -  regularization                : Boolean variable determining whether regularization is done. Default is True.\n",
        "      -  numerical_gradients           : Boolean variable which determines whether numerical gradients are used when\n",
        "                                         solving the max. likelihood optimization problem. Default is True.\n",
        "      -  fname                         : Filename for saving (.pickle extension)\n",
        "      - overwrite                      : Option determining whether any existing file with the same name supplied in 'fname'  \n",
        "                                         should be overwritten."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "For this demonstration, we will train a Kriging model with regularization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "krg_class = KrigingModel(XY_data=brainin_data, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 3: Extract variable names (optional)\n",
        "Next, we extract Pyomo variable names from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars = krg_class.get_feature_vector()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 4: Train the Kriging surrogate\n",
        "Next, we train the RBF surrogate by calling ``kriging_training``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = krg_class.kriging_training()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The returned information correspond to the Kriging model parameters.\n",
        "\n",
        "As we can see, the optimization problem was solved using SciPy's L-BFGS algorithm which makes use of gradients. A different algorithm  (Basinhopping) is used when no numerical gradients are computed (when numerical_gradients is set to False). The user should try this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 5: View model metrics\n",
        "    \n",
        "We can view the RMSE and $R^2$ values of the Kriging fit based on the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('R2: ', result.training_R2, '\\nRMSE: ', result.training_rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 6 (Optional): Generate Pyomo expression output at any unsampled point\n",
        "\n",
        "\n",
        "Again, based on the model we trained, we evaluate the surrogate at a set of  off-design points:\n",
        "\n",
        "- $x_{1}=5$, $x_{2}=8$   (true function value: 57.9908)\n",
        "- $x_{1}=-3$, $x_{2}=10$ (true function value: 4.2461)\n",
        "- $x_{1}=-2$, $x_{2}=3$  (true function value: 50.8899)\n",
        "\n",
        "We do this by calling the function ``kriging_predict_output``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "unsampled_points = np.array([ [5, 8], [-3, 10], [-2, 3]])\n",
        "ys = krg_class.kriging_predict_output(result, unsampled_points)\n",
        "print(ys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Kriging model performs very well, predicting all three points fairly accurately. \n",
        "\n",
        "For RBF models, the Pyomo expression is generated by calling ``kriging_generate_expression`` on the results object: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(result.kriging_generate_expression([m.x[1], m.x[2]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, expressing a Kriging model algebraically is pretty complicated!\n",
        "\n",
        "Parity plots for the Kriging model may be viewed with the ``parity_residual_plots`` method.\n",
        "\n",
        "Further information about using PySMO's Krigng tool and features can be found in the [documentation](https://idaes-pse.readthedocs.io/en/stable/surrogate/pysmo/pysmo_kriging.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "PySMO allows IDAES users to sample design spaces and generate different types of surrogate models. Further information about PySMO's capabilities may be found in the documentation."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}